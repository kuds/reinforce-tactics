{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kuds/reinforce-tactics/blob/main/notebooks/llm_bot_tournament.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# ü§ñ LLM Bot Tournament - Reinforce Tactics\n",
        "\n",
        "Run interactive tournaments between LLM-powered bots (OpenAI GPT, Claude, Gemini) and the SimpleBot!\n",
        "\n",
        "**Features:**\n",
        "- üéÆ Single game runner with detailed turn-by-turn logging\n",
        "- üèÜ Round-robin tournament system with multiple games per matchup\n",
        "- üîë Flexible API key configuration (environment variables or Google Colab secrets)\n",
        "- üìä Comprehensive statistics: wins, losses, draws, win rates\n",
        "- üéØ Customizable model selection (GPT-4o, Claude Sonnet, Gemini Pro, etc.)\n",
        "- üó∫Ô∏è Support for all map sizes (6x6 beginner to 32x32 expert)\n",
        "\n",
        "**Supported Bots:**\n",
        "- **SimpleBot**: Built-in rule-based bot (always available)\n",
        "- **OpenAIBot**: Uses OpenAI GPT models (requires `OPENAI_API_KEY`)\n",
        "- **ClaudeBot**: Uses Anthropic Claude models (requires `ANTHROPIC_API_KEY`)\n",
        "- **GeminiBot**: Uses Google Gemini models (requires `GOOGLE_API_KEY`)\n",
        "\n",
        "**Quick Start:**\n",
        "1. Install dependencies and clone the repository\n",
        "2. Configure API keys for the bots you want to use\n",
        "3. Run a single game or full tournament\n",
        "4. Analyze the results!\n",
        "\n",
        "**Estimated API Costs:**\n",
        "- **GPT-4o-mini**: ~$0.0001-0.0005 per game (recommended for testing)\n",
        "- **Claude Haiku**: ~$0.0001-0.0003 per game (recommended for testing)\n",
        "- **Gemini Flash**: Free tier available, ~$0.0001 per game\n",
        "- **GPT-4o**: ~$0.005-0.02 per game (stronger play, higher cost)\n",
        "- **Claude Sonnet**: ~$0.003-0.015 per game (stronger play, higher cost)\n",
        "\n",
        "*Costs vary based on game length and map complexity. Use mini/haiku/flash models for testing!*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup"
      },
      "source": [
        "## üì¶ Setup and Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clone_repo"
      },
      "source": [
        "# Clone the Reinforce Tactics repository if not already present\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "if not Path('reinforce-tactics').exists():\n",
        "    print(\"üì• Cloning Reinforce Tactics repository...\")\n",
        "    !git clone https://github.com/kuds/reinforce-tactics.git\n",
        "    print(\"‚úÖ Repository cloned!\")\n",
        "else:\n",
        "    print(\"‚úÖ Repository already cloned\")\n",
        "\n",
        "# Change to repository directory\n",
        "os.chdir('reinforce-tactics')\n",
        "print(f\"\\nüìÇ Current directory: {os.getcwd()}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "install_llm_deps"
      },
      "source": [
        "# Install LLM bot dependencies\n",
        "# These are optional - only install for the bots you plan to use\n",
        "print(\"üì¶ Installing LLM dependencies...\\n\")\n",
        "\n",
        "# Install OpenAI (for GPT models)\n",
        "print(\"Installing OpenAI...\")\n",
        "!pip install -q openai>=1.0.0\n",
        "\n",
        "# Install Anthropic (for Claude models)\n",
        "print(\"Installing Anthropic...\")\n",
        "!pip install -q anthropic>=0.18.0\n",
        "\n",
        "# Install Google Generative AI (for Gemini models)\n",
        "print(\"Installing Google Generative AI...\")\n",
        "!pip install -q google-generativeai>=0.4.0\n",
        "\n",
        "# Install other dependencies if needed\n",
        "!pip install -q pandas numpy\n",
        "\n",
        "print(\"\\n‚úÖ All LLM dependencies installed!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "add_to_path"
      },
      "source": [
        "# Add repository to Python path\n",
        "import sys\n",
        "repo_path = os.getcwd()\n",
        "if repo_path not in sys.path:\n",
        "    sys.path.insert(0, repo_path)\n",
        "    print(f\"‚úÖ Added to Python path: {repo_path}\")\n",
        "else:\n",
        "    print(f\"‚úÖ Already in Python path: {repo_path}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "api_keys"
      },
      "source": [
        "## üîë API Key Configuration\n",
        "\n",
        "You have two options for setting API keys:\n",
        "\n",
        "### Option 1: Direct Environment Variables (Quick Setup)\n",
        "Set API keys directly in the cells below. **Note:** These will be visible in the notebook.\n",
        "\n",
        "### Option 2: Google Colab Secrets (Recommended for Colab)\n",
        "1. Click the üîë key icon in the left sidebar\n",
        "2. Add secrets with names: `OPENAI_API_KEY`, `ANTHROPIC_API_KEY`, `GOOGLE_API_KEY`\n",
        "3. Toggle \"Notebook access\" on for each secret\n",
        "\n",
        "The code below will check both sources and use Colab secrets if available."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "set_api_keys"
      },
      "source": [
        "import os\n",
        "\n",
        "# Try to use Google Colab secrets first\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    print(\"‚úÖ Google Colab detected - checking for secrets...\\n\")\n",
        "\n",
        "    # Try to get OpenAI key from secrets\n",
        "    try:\n",
        "        openai_key = userdata.get('OPENAI_API_KEY')\n",
        "        os.environ['OPENAI_API_KEY'] = openai_key\n",
        "        print(\"‚úÖ OPENAI_API_KEY loaded from Colab secrets\")\n",
        "    except:\n",
        "        if 'OPENAI_API_KEY' not in os.environ:\n",
        "            print(\"‚ö†Ô∏è  OPENAI_API_KEY not found in Colab secrets\")\n",
        "\n",
        "    # Try to get Anthropic key from secrets\n",
        "    try:\n",
        "        anthropic_key = userdata.get('ANTHROPIC_API_KEY')\n",
        "        os.environ['ANTHROPIC_API_KEY'] = anthropic_key\n",
        "        print(\"‚úÖ ANTHROPIC_API_KEY loaded from Colab secrets\")\n",
        "    except:\n",
        "        if 'ANTHROPIC_API_KEY' not in os.environ:\n",
        "            print(\"‚ö†Ô∏è  ANTHROPIC_API_KEY not found in Colab secrets\")\n",
        "\n",
        "    # Try to get Google key from secrets\n",
        "    try:\n",
        "        google_key = userdata.get('GOOGLE_API_KEY')\n",
        "        os.environ['GOOGLE_API_KEY'] = google_key\n",
        "        print(\"‚úÖ GOOGLE_API_KEY loaded from Colab secrets\")\n",
        "    except:\n",
        "        if 'GOOGLE_API_KEY' not in os.environ:\n",
        "            print(\"‚ö†Ô∏è  GOOGLE_API_KEY not found in Colab secrets\")\n",
        "\n",
        "except ImportError:\n",
        "    print(\"‚ÑπÔ∏è  Not running in Google Colab - using environment variables\")\n",
        "\n",
        "# Option 1: Set API keys directly (if not using Colab secrets)\n",
        "# Uncomment and set your keys below if needed:\n",
        "\n",
        "# os.environ['OPENAI_API_KEY'] = 'sk-...'\n",
        "# os.environ['ANTHROPIC_API_KEY'] = 'sk-ant-...'\n",
        "# os.environ['GOOGLE_API_KEY'] = 'AI...'\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"API Key Status:\")\n",
        "print(\"=\"*60)\n",
        "print(f\"OpenAI:    {'‚úÖ Configured' if os.environ.get('OPENAI_API_KEY') else '‚ùå Not set'}\")\n",
        "print(f\"Anthropic: {'‚úÖ Configured' if os.environ.get('ANTHROPIC_API_KEY') else '‚ùå Not set'}\")\n",
        "print(f\"Google:    {'‚úÖ Configured' if os.environ.get('GOOGLE_API_KEY') else '‚ùå Not set'}\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\n‚ÑπÔ∏è  You can run tournaments with any bots that have API keys configured.\")\n",
        "print(\"   SimpleBot is always available and doesn't require an API key.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imports"
      },
      "source": [
        "## üìö Import Required Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "import_modules"
      },
      "source": [
        "import logging\n",
        "from collections import defaultdict\n",
        "from typing import Dict, List, Any, Optional, Tuple, Union\n",
        "\n",
        "# Configure logging to see bot actions\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "\n",
        "# Import game components\n",
        "from reinforcetactics.core.game_state import GameState\n",
        "from reinforcetactics.game.bot import SimpleBot\n",
        "from reinforcetactics.utils.file_io import FileIO\n",
        "\n",
        "# Import LLM bots (with graceful fallback)\n",
        "llm_bots_available = {}\n",
        "\n",
        "try:\n",
        "    from reinforcetactics.game.llm_bot import OpenAIBot\n",
        "    llm_bots_available['openai'] = OpenAIBot\n",
        "    print(\"‚úÖ OpenAIBot available\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ö†Ô∏è  OpenAIBot not available: {e}\")\n",
        "\n",
        "try:\n",
        "    from reinforcetactics.game.llm_bot import ClaudeBot\n",
        "    llm_bots_available['claude'] = ClaudeBot\n",
        "    print(\"‚úÖ ClaudeBot available\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ö†Ô∏è  ClaudeBot not available: {e}\")\n",
        "\n",
        "try:\n",
        "    from reinforcetactics.game.llm_bot import GeminiBot\n",
        "    llm_bots_available['gemini'] = GeminiBot\n",
        "    print(\"‚úÖ GeminiBot available\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ö†Ô∏è  GeminiBot not available: {e}\")\n",
        "\n",
        "print(f\"\\n‚úÖ Imports complete! {len(llm_bots_available)} LLM bot types available.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "single_game"
      },
      "source": [
        "## üéÆ Single Game Runner\n",
        "\n",
        "Run a single game between two bots with detailed logging."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "run_single_game_function"
      },
      "source": [
        "def run_single_game(\n",
        "    player1_bot: Union[str, type],\n",
        "    player2_bot: Union[str, type],\n",
        "    map_file: str = 'maps/1v1/6x6_beginner.csv',\n",
        "    max_turns: int = 500,\n",
        "    verbose: bool = True,\n",
        "    player1_model: Optional[str] = None,\n",
        "    player2_model: Optional[str] = None\n",
        ") -> int:\n",
        "    \"\"\"\n",
        "    Run a single game between two bots.\n",
        "\n",
        "    Args:\n",
        "        player1_bot: Bot class or 'simple' for SimpleBot (plays as Player 1)\n",
        "        player2_bot: Bot class or 'simple' for SimpleBot (plays as Player 2)\n",
        "        map_file: Path to map file (default: maps/1v1/6x6_beginner.csv)\n",
        "        max_turns: Maximum number of turns to prevent infinite games (default: 500)\n",
        "        verbose: Show turn-by-turn details (default: True)\n",
        "        player1_model: Optional model name for player 1 LLM bot\n",
        "        player2_model: Optional model name for player 2 LLM bot\n",
        "\n",
        "    Returns:\n",
        "        Winner: 1 (player 1 wins), 2 (player 2 wins), or 0 (draw)\n",
        "    \"\"\"\n",
        "    # Load map\n",
        "    map_data = FileIO.load_map(map_file)\n",
        "    if map_data is None:\n",
        "        raise ValueError(f\"Failed to load map: {map_file}\")\n",
        "\n",
        "    # Create game state\n",
        "    game_state = GameState(map_data, num_players=2)\n",
        "\n",
        "    # Create bot instances\n",
        "    def create_bot(bot_spec, player_num, model=None):\n",
        "        if bot_spec == 'simple' or bot_spec is None:\n",
        "            return SimpleBot(game_state, player_num)\n",
        "        else:\n",
        "            # It's an LLM bot class\n",
        "            if model:\n",
        "                return bot_spec(game_state, player_num, model=model)\n",
        "            else:\n",
        "                return bot_spec(game_state, player_num)\n",
        "\n",
        "    bot1 = create_bot(player1_bot, 1, player1_model)\n",
        "    bot2 = create_bot(player2_bot, 2, player2_model)\n",
        "    bots = {1: bot1, 2: bot2}\n",
        "\n",
        "    # Get bot names\n",
        "    bot1_name = bot1.__class__.__name__\n",
        "    bot2_name = bot2.__class__.__name__\n",
        "\n",
        "    if verbose:\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(f\"Game Start: {bot1_name} (P1) vs {bot2_name} (P2)\")\n",
        "        print(f\"Map: {map_file}\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "    # Play the game\n",
        "    turn_count = 0\n",
        "    last_gold = {1: game_state.player_gold[1], 2: game_state.player_gold[2]}\n",
        "\n",
        "    while not game_state.game_over and turn_count < max_turns:\n",
        "        current_player = game_state.current_player\n",
        "        current_bot = bots[current_player]\n",
        "        bot_name = bot1_name if current_player == 1 else bot2_name\n",
        "\n",
        "        # Show turn info\n",
        "        if verbose:\n",
        "            print(f\"\\n--- Turn {turn_count + 1} - {bot_name} (P{current_player}) ---\")\n",
        "            print(f\"  Gold: P1={game_state.player_gold[1]}, P2={game_state.player_gold[2]}\")\n",
        "\n",
        "        # Bot takes turn\n",
        "        try:\n",
        "            current_bot.take_turn()\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è  Error during {bot_name} turn: {e}\")\n",
        "            # Bot forfeits on error\n",
        "            game_state.game_over = True\n",
        "            game_state.winner = 1 if current_player == 2 else 2\n",
        "            break\n",
        "\n",
        "        # Show gold changes\n",
        "        if verbose:\n",
        "            gold_change = game_state.player_gold[current_player] - last_gold[current_player]\n",
        "            if gold_change != 0:\n",
        "                print(f\"  Gold change: {gold_change:+d}\")\n",
        "            last_gold[current_player] = game_state.player_gold[current_player]\n",
        "\n",
        "        turn_count += 1\n",
        "\n",
        "        # Check for game over\n",
        "        if game_state.game_over:\n",
        "            break\n",
        "\n",
        "    # Determine winner\n",
        "    if game_state.game_over and game_state.winner:\n",
        "        winner = game_state.winner\n",
        "        winner_name = bot1_name if winner == 1 else bot2_name\n",
        "    elif turn_count >= max_turns:\n",
        "        winner = 0\n",
        "        winner_name = \"Draw (max turns)\"\n",
        "    else:\n",
        "        winner = 0\n",
        "        winner_name = \"Draw\"\n",
        "\n",
        "    if verbose:\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(f\"Game Over! Winner: {winner_name}\")\n",
        "        print(f\"Total turns: {turn_count}\")\n",
        "        print(f\"Final gold - P1: {game_state.player_gold[1]}, P2: {game_state.player_gold[2]}\")\n",
        "        print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "    return winner\n",
        "\n",
        "print(\"‚úÖ run_single_game() function defined\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tournament"
      },
      "source": [
        "## üèÜ Tournament Runner\n",
        "\n",
        "Run a round-robin tournament between multiple bots."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "run_tournament_function"
      },
      "source": [
        "def run_tournament(\n",
        "    bots: List[Tuple[str, Union[str, type], Optional[str]]],\n",
        "    map_file: str = 'maps/1v1/6x6_beginner.csv',\n",
        "    games_per_matchup: int = 2,\n",
        "    max_turns: int = 500\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Run a round-robin tournament between multiple bots.\n",
        "\n",
        "    Args:\n",
        "        bots: List of (name, bot_class_or_'simple', optional_model) tuples\n",
        "        map_file: Path to map file (default: maps/1v1/6x6_beginner.csv)\n",
        "        games_per_matchup: Games per side (total = 2 * games_per_matchup)\n",
        "        max_turns: Maximum turns per game (default: 500)\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with tournament results and standings\n",
        "\n",
        "    Example:\n",
        "        bots = [\n",
        "            ('SimpleBot', 'simple', None),\n",
        "            ('GPT-4o-mini', OpenAIBot, 'gpt-4o-mini'),\n",
        "            ('Claude', ClaudeBot, None)  # Uses default model\n",
        "        ]\n",
        "        results = run_tournament(bots)\n",
        "    \"\"\"\n",
        "    if len(bots) < 2:\n",
        "        raise ValueError(\"Need at least 2 bots for a tournament\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(f\"üèÜ TOURNAMENT START\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"Map: {map_file}\")\n",
        "    print(f\"Participants: {len(bots)}\")\n",
        "    for name, bot_type, model in bots:\n",
        "        model_str = f\" ({model})\" if model else \"\"\n",
        "        bot_type_str = \"SimpleBot\" if bot_type == 'simple' else bot_type.__name__\n",
        "        print(f\"  - {name}: {bot_type_str}{model_str}\")\n",
        "    print(f\"Games per matchup: {games_per_matchup * 2} ({games_per_matchup} per side)\")\n",
        "    print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "    # Initialize results tracking\n",
        "    results = defaultdict(lambda: {'wins': 0, 'losses': 0, 'draws': 0})\n",
        "    matchup_details = []\n",
        "\n",
        "    # Generate all matchups (round-robin)\n",
        "    matchups = []\n",
        "    for i in range(len(bots)):\n",
        "        for j in range(i + 1, len(bots)):\n",
        "            matchups.append((i, j))\n",
        "\n",
        "    total_games = len(matchups) * games_per_matchup * 2\n",
        "    print(f\"üìä Total matchups: {len(matchups)}\")\n",
        "    print(f\"üìä Total games: {total_games}\\n\")\n",
        "\n",
        "    game_num = 0\n",
        "\n",
        "    # Run all matchups\n",
        "    for matchup_idx, (i, j) in enumerate(matchups, 1):\n",
        "        bot1_name, bot1_class, bot1_model = bots[i]\n",
        "        bot2_name, bot2_class, bot2_model = bots[j]\n",
        "\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"Matchup {matchup_idx}/{len(matchups)}: {bot1_name} vs {bot2_name}\")\n",
        "        print(f\"{'='*70}\")\n",
        "\n",
        "        matchup_results = {\n",
        "            'bot1': bot1_name,\n",
        "            'bot2': bot2_name,\n",
        "            'bot1_wins': 0,\n",
        "            'bot2_wins': 0,\n",
        "            'draws': 0\n",
        "        }\n",
        "\n",
        "        # Play games_per_matchup with bot1 as player 1\n",
        "        for game in range(games_per_matchup):\n",
        "            game_num += 1\n",
        "            print(f\"\\n  Game {game_num}/{total_games}: {bot1_name} (P1) vs {bot2_name} (P2)\")\n",
        "\n",
        "            winner = run_single_game(\n",
        "                bot1_class, bot2_class,\n",
        "                map_file=map_file,\n",
        "                max_turns=max_turns,\n",
        "                verbose=False,\n",
        "                player1_model=bot1_model,\n",
        "                player2_model=bot2_model\n",
        "            )\n",
        "\n",
        "            if winner == 1:\n",
        "                results[bot1_name]['wins'] += 1\n",
        "                results[bot2_name]['losses'] += 1\n",
        "                matchup_results['bot1_wins'] += 1\n",
        "                print(f\"    ‚úÖ {bot1_name} wins!\")\n",
        "            elif winner == 2:\n",
        "                results[bot2_name]['wins'] += 1\n",
        "                results[bot1_name]['losses'] += 1\n",
        "                matchup_results['bot2_wins'] += 1\n",
        "                print(f\"    ‚úÖ {bot2_name} wins!\")\n",
        "            else:\n",
        "                results[bot1_name]['draws'] += 1\n",
        "                results[bot2_name]['draws'] += 1\n",
        "                matchup_results['draws'] += 1\n",
        "                print(f\"    ‚öñÔ∏è  Draw\")\n",
        "\n",
        "        # Play games_per_matchup with bot2 as player 1 (swap sides)\n",
        "        for game in range(games_per_matchup):\n",
        "            game_num += 1\n",
        "            print(f\"\\n  Game {game_num}/{total_games}: {bot2_name} (P1) vs {bot1_name} (P2)\")\n",
        "\n",
        "            winner = run_single_game(\n",
        "                bot2_class, bot1_class,\n",
        "                map_file=map_file,\n",
        "                max_turns=max_turns,\n",
        "                verbose=False,\n",
        "                player1_model=bot2_model,\n",
        "                player2_model=bot1_model\n",
        "            )\n",
        "\n",
        "            if winner == 1:\n",
        "                results[bot2_name]['wins'] += 1\n",
        "                results[bot1_name]['losses'] += 1\n",
        "                matchup_results['bot2_wins'] += 1\n",
        "                print(f\"    ‚úÖ {bot2_name} wins!\")\n",
        "            elif winner == 2:\n",
        "                results[bot1_name]['wins'] += 1\n",
        "                results[bot2_name]['losses'] += 1\n",
        "                matchup_results['bot1_wins'] += 1\n",
        "                print(f\"    ‚úÖ {bot1_name} wins!\")\n",
        "            else:\n",
        "                results[bot1_name]['draws'] += 1\n",
        "                results[bot2_name]['draws'] += 1\n",
        "                matchup_results['draws'] += 1\n",
        "                print(f\"    ‚öñÔ∏è  Draw\")\n",
        "\n",
        "        # Show matchup summary\n",
        "        print(f\"\\n  Matchup Summary: {bot1_name} {matchup_results['bot1_wins']}-{matchup_results['bot2_wins']}-{matchup_results['draws']} {bot2_name}\")\n",
        "        matchup_details.append(matchup_results)\n",
        "\n",
        "    # Calculate final standings\n",
        "    standings = []\n",
        "    for bot_name, stats in results.items():\n",
        "        total_games = stats['wins'] + stats['losses'] + stats['draws']\n",
        "        win_rate = stats['wins'] / total_games if total_games > 0 else 0.0\n",
        "\n",
        "        standings.append({\n",
        "            'name': bot_name,\n",
        "            'wins': stats['wins'],\n",
        "            'losses': stats['losses'],\n",
        "            'draws': stats['draws'],\n",
        "            'total': total_games,\n",
        "            'win_rate': win_rate\n",
        "        })\n",
        "\n",
        "    # Sort by wins (descending), then win_rate\n",
        "    standings.sort(key=lambda x: (x['wins'], x['win_rate']), reverse=True)\n",
        "\n",
        "    # Display final standings\n",
        "    print(\"\\n\\n\" + \"=\"*70)\n",
        "    print(\"üèÜ FINAL STANDINGS\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"{'Rank':<6}{'Bot':<25}{'Wins':<8}{'Losses':<8}{'Draws':<8}{'Win Rate':<10}\")\n",
        "    print(\"-\"*70)\n",
        "\n",
        "    for rank, standing in enumerate(standings, 1):\n",
        "        medal = \"ü•á\" if rank == 1 else (\"ü•à\" if rank == 2 else (\"ü•â\" if rank == 3 else \"  \"))\n",
        "        print(f\"{medal} {rank:<3}{standing['name']:<25}{standing['wins']:<8}{standing['losses']:<8}\"\n",
        "              f\"{standing['draws']:<8}{standing['win_rate']:.3f}\")\n",
        "\n",
        "    print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "    return {\n",
        "        'standings': standings,\n",
        "        'matchups': matchup_details,\n",
        "        'map': map_file,\n",
        "        'games_per_matchup': games_per_matchup\n",
        "    }\n",
        "\n",
        "print(\"‚úÖ run_tournament() function defined\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "examples"
      },
      "source": [
        "## üéØ Example Usage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "example_single_game"
      },
      "source": [
        "### Example 1: Single Game - SimpleBot vs SimpleBot\n",
        "\n",
        "Let's start with a simple game between two SimpleBots to test the system."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "run_example_simple"
      },
      "source": [
        "# Run a single game: SimpleBot vs SimpleBot\n",
        "winner = run_single_game(\n",
        "    player1_bot='simple',\n",
        "    player2_bot='simple',\n",
        "    map_file='maps/1v1/6x6_beginner.csv',\n",
        "    max_turns=100,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(f\"\\nWinner: Player {winner}\" if winner else \"\\nResult: Draw\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "example_llm_game"
      },
      "source": [
        "### Example 2: Single Game - LLM Bot vs SimpleBot\n",
        "\n",
        "Test an LLM bot against SimpleBot. Make sure you have the appropriate API key configured!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "run_example_llm"
      },
      "source": [
        "# Run a single game: OpenAI Bot vs SimpleBot\n",
        "# Uncomment and run if you have OpenAI API key configured\n",
        "\n",
        "# if 'openai' in llm_bots_available:\n",
        "#     winner = run_single_game(\n",
        "#         player1_bot=llm_bots_available['openai'],\n",
        "#         player2_bot='simple',\n",
        "#         map_file='maps/1v1/6x6_beginner.csv',\n",
        "#         max_turns=100,\n",
        "#         verbose=True,\n",
        "#         player1_model='gpt-4o-mini'  # Use mini model for lower cost\n",
        "#     )\n",
        "#     print(f\"\\nWinner: Player {winner}\" if winner else \"\\nResult: Draw\")\n",
        "# else:\n",
        "#     print(\"‚ö†Ô∏è  OpenAIBot not available. Please install openai and configure API key.\")\n",
        "\n",
        "print(\"Uncomment the code above to run an LLM bot game\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "example_tournament"
      },
      "source": [
        "### Example 3: Mini Tournament\n",
        "\n",
        "Run a small tournament with available bots."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "run_example_tournament"
      },
      "source": [
        "# Define tournament participants\n",
        "# Format: (display_name, bot_class_or_'simple', optional_model_name)\n",
        "\n",
        "tournament_bots = [\n",
        "    ('SimpleBot', 'simple', None),\n",
        "]\n",
        "\n",
        "# Add LLM bots if available and configured\n",
        "if 'openai' in llm_bots_available and os.environ.get('OPENAI_API_KEY'):\n",
        "    tournament_bots.append(('GPT-4o-mini', llm_bots_available['openai'], 'gpt-4o-mini'))\n",
        "\n",
        "if 'claude' in llm_bots_available and os.environ.get('ANTHROPIC_API_KEY'):\n",
        "    tournament_bots.append(('Claude Haiku', llm_bots_available['claude'], 'claude-3-haiku-20240307'))\n",
        "\n",
        "if 'gemini' in llm_bots_available and os.environ.get('GOOGLE_API_KEY'):\n",
        "    tournament_bots.append(('Gemini Flash', llm_bots_available['gemini'], 'gemini-1.5-flash'))\n",
        "\n",
        "# Run tournament if we have at least 2 bots\n",
        "if len(tournament_bots) >= 2:\n",
        "    results = run_tournament(\n",
        "        bots=tournament_bots,\n",
        "        map_file='maps/1v1/6x6_beginner.csv',\n",
        "        games_per_matchup=2,  # 2 games per side = 4 total per matchup\n",
        "        max_turns=100\n",
        "    )\n",
        "    print(\"\\n‚úÖ Tournament complete! Results saved in 'results' variable.\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Need at least 2 bots for a tournament.\")\n",
        "    print(\"   Configure API keys for LLM bots or add more SimpleBots for testing.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "custom_models"
      },
      "source": [
        "## üé® Custom Model Configuration\n",
        "\n",
        "You can specify different models for each LLM provider. Here are some examples:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "openai_models"
      },
      "source": [
        "### OpenAI Models\n",
        "\n",
        "**Available models:**\n",
        "- `gpt-4o-mini` (default) - Fastest and cheapest, good for testing\n",
        "- `gpt-4o` - More capable, higher cost\n",
        "- `gpt-4-turbo` - Previous generation, balanced\n",
        "\n",
        "**Example:**\n",
        "```python\n",
        "# Using GPT-4o for stronger gameplay\n",
        "winner = run_single_game(\n",
        "    player1_bot=OpenAIBot,\n",
        "    player2_bot='simple',\n",
        "    player1_model='gpt-4o'\n",
        ")\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "claude_models"
      },
      "source": [
        "### Claude Models\n",
        "\n",
        "**Available models:**\n",
        "- `claude-3-haiku-20240307` (default) - Fastest and cheapest\n",
        "- `claude-3-5-sonnet-20241022` - Most capable, balanced cost\n",
        "- `claude-3-opus-20240229` - Highest capability, highest cost\n",
        "\n",
        "**Example:**\n",
        "```python\n",
        "# Using Claude Sonnet for better strategic play\n",
        "winner = run_single_game(\n",
        "    player1_bot=ClaudeBot,\n",
        "    player2_bot='simple',\n",
        "    player1_model='claude-3-5-sonnet-20241022'\n",
        ")\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gemini_models"
      },
      "source": [
        "### Gemini Models\n",
        "\n",
        "**Available models:**\n",
        "- `gemini-1.5-flash` (default) - Fast and efficient, free tier available\n",
        "- `gemini-1.5-pro` - More capable, higher cost\n",
        "- `gemini-2.0-flash-exp` - Experimental, cutting edge\n",
        "\n",
        "**Example:**\n",
        "```python\n",
        "# Using Gemini Pro for better performance\n",
        "winner = run_single_game(\n",
        "    player1_bot=GeminiBot,\n",
        "    player2_bot='simple',\n",
        "    player1_model='gemini-1.5-pro'\n",
        ")\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "custom_tournament_example"
      },
      "source": [
        "### Example: Tournament with Custom Models\n",
        "\n",
        "Compare different models from different providers:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "run_custom_tournament"
      },
      "source": [
        "# Advanced tournament: Compare different models\n",
        "# Only run this if you have all API keys configured and don't mind the cost!\n",
        "\n",
        "# advanced_bots = [\n",
        "#     ('SimpleBot', 'simple', None),\n",
        "#     ('GPT-4o-mini', OpenAIBot, 'gpt-4o-mini'),\n",
        "#     ('GPT-4o', OpenAIBot, 'gpt-4o'),\n",
        "#     ('Claude Haiku', ClaudeBot, 'claude-3-haiku-20240307'),\n",
        "#     ('Claude Sonnet', ClaudeBot, 'claude-3-5-sonnet-20241022'),\n",
        "#     ('Gemini Flash', GeminiBot, 'gemini-1.5-flash'),\n",
        "#     ('Gemini Pro', GeminiBot, 'gemini-1.5-pro'),\n",
        "# ]\n",
        "\n",
        "# results = run_tournament(\n",
        "#     bots=advanced_bots,\n",
        "#     map_file='maps/1v1/6x6_beginner.csv',\n",
        "#     games_per_matchup=2,\n",
        "#     max_turns=100\n",
        "# )\n",
        "\n",
        "print(\"Uncomment the code above to run a full model comparison tournament\")\n",
        "print(\"‚ö†Ô∏è  Warning: This will make many API calls and may incur costs!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "documentation"
      },
      "source": [
        "## üìñ Documentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cost_estimates"
      },
      "source": [
        "### üí∞ API Cost Estimates\n",
        "\n",
        "**OpenAI Pricing (approximate, as of 2024):**\n",
        "- GPT-4o-mini: $0.15/1M input tokens, $0.60/1M output tokens\n",
        "- GPT-4o: $2.50/1M input tokens, $10.00/1M output tokens\n",
        "- Typical game: 2,000-10,000 tokens per side\n",
        "- **Cost per game:** $0.0001-0.0005 (mini), $0.005-0.02 (4o)\n",
        "\n",
        "**Anthropic Pricing:**\n",
        "- Claude Haiku: $0.25/1M input tokens, $1.25/1M output tokens\n",
        "- Claude Sonnet: $3.00/1M input tokens, $15.00/1M output tokens\n",
        "- **Cost per game:** $0.0001-0.0003 (Haiku), $0.003-0.015 (Sonnet)\n",
        "\n",
        "**Google Gemini Pricing:**\n",
        "- Gemini Flash: Free tier available (15 RPM), $0.075/1M input, $0.30/1M output\n",
        "- Gemini Pro: $1.25/1M input tokens, $5.00/1M output tokens\n",
        "- **Cost per game:** ~$0 (Flash free tier), $0.0001-0.001 (Flash paid), $0.001-0.005 (Pro)\n",
        "\n",
        "**Tournament Cost Estimates:**\n",
        "- 3 bots, 2 games/matchup: 12 games total\n",
        "- Using mini/haiku/flash: ~$0.001-0.01 total\n",
        "- Using premium models: ~$0.05-0.20 total\n",
        "\n",
        "**Cost Saving Tips:**\n",
        "1. Use mini/haiku/flash models for development and testing\n",
        "2. Use smaller maps (6x6) which need fewer tokens\n",
        "3. Set lower `max_turns` to prevent long games\n",
        "4. Use Gemini Flash free tier for unlimited testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "performance_tips"
      },
      "source": [
        "### ‚ö° Performance Tips\n",
        "\n",
        "**Model Selection for Different Purposes:**\n",
        "\n",
        "**For Testing & Development:**\n",
        "- ‚úÖ GPT-4o-mini - Fast, cheap, decent strategy\n",
        "- ‚úÖ Claude Haiku - Very fast, cheap, good baseline\n",
        "- ‚úÖ Gemini Flash - Free tier, fast, great for testing\n",
        "\n",
        "**For Competitive Play:**\n",
        "- üèÜ GPT-4o - Strong strategic thinking\n",
        "- üèÜ Claude Sonnet 3.5 - Excellent reasoning, good value\n",
        "- üèÜ Gemini Pro 1.5 - Good balance of cost/performance\n",
        "\n",
        "**For Research/Analysis:**\n",
        "- üî¨ Claude Opus - Highest reasoning capability\n",
        "- üî¨ GPT-4 Turbo - Consistent performance\n",
        "\n",
        "**Game Speed:**\n",
        "- Smaller maps (6x6) complete in 1-3 minutes per game\n",
        "- Larger maps (32x32) can take 10-30 minutes per game\n",
        "- LLM API calls add 1-5 seconds per turn\n",
        "- SimpleBot is nearly instant\n",
        "\n",
        "**Tournament Duration Estimates:**\n",
        "- 2 bots, 4 games: ~5-15 minutes\n",
        "- 3 bots, 12 games: ~15-45 minutes\n",
        "- 4 bots, 24 games: ~30-90 minutes\n",
        "- 5 bots, 40 games: ~1-2 hours\n",
        "\n",
        "**Optimization Strategies:**\n",
        "1. Start with 6x6 maps for quick iterations\n",
        "2. Use `games_per_matchup=1` for initial testing\n",
        "3. Set `max_turns=100` for faster games\n",
        "4. Run tournaments with fewer bots initially\n",
        "5. Use verbose=False in run_single_game() to reduce output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "troubleshooting"
      },
      "source": [
        "### üîß Troubleshooting\n",
        "\n",
        "**Problem: \"API key not provided\" error**\n",
        "- **Solution:** Make sure you've set the API key in the environment or Colab secrets\n",
        "- Check the API Key Configuration section output\n",
        "- Uncomment and set the API key directly in the configuration cell\n",
        "\n",
        "**Problem: \"openai package not installed\" error**\n",
        "- **Solution:** Run the installation cell again\n",
        "- Or manually install: `!pip install openai>=1.0.0`\n",
        "\n",
        "**Problem: Bot makes invalid moves or errors**\n",
        "- **Solution:** This is expected occasionally with LLMs\n",
        "- The game will skip invalid actions and continue\n",
        "- Try using a more capable model (e.g., GPT-4o instead of mini)\n",
        "- Check the logs to see what actions failed\n",
        "\n",
        "**Problem: Games taking too long**\n",
        "- **Solution:** Reduce `max_turns` parameter\n",
        "- Use smaller maps (6x6 instead of 32x32)\n",
        "- Faster models: Haiku, Flash, or mini\n",
        "\n",
        "**Problem: API rate limits exceeded**\n",
        "- **Solution:** Add delays between games\n",
        "- Use free tier models (Gemini Flash)\n",
        "- Reduce `games_per_matchup`\n",
        "- Spread tournament over multiple sessions\n",
        "\n",
        "**Problem: Out of memory error**\n",
        "- **Solution:** Restart the notebook runtime\n",
        "- Run fewer games at once\n",
        "- Use smaller maps\n",
        "\n",
        "**Problem: \"Map file not found\" error**\n",
        "- **Solution:** Make sure you're in the reinforce-tactics directory\n",
        "- Check the path: `!ls maps/1v1/`\n",
        "- Use absolute paths if needed\n",
        "\n",
        "**Problem: Import errors for LLM bots**\n",
        "- **Solution:** Check that dependencies installed correctly\n",
        "- Verify the repository was cloned successfully\n",
        "- Make sure the repository is in your Python path\n",
        "\n",
        "**Problem: Tournament results seem random**\n",
        "- **Solution:** LLMs have inherent randomness\n",
        "- Increase `games_per_matchup` for more stable results\n",
        "- Temperature parameter affects consistency (set in llm_bot.py)\n",
        "- SimpleBot is deterministic and provides a good baseline\n",
        "\n",
        "**Problem: Cost concerns**\n",
        "- **Solution:** Always use mini/haiku/flash for testing\n",
        "- Monitor API usage in your provider dashboard\n",
        "- Set spending limits in your API account\n",
        "- Test with SimpleBot first (free)\n",
        "- Use Gemini Flash free tier for unlimited testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "advanced"
      },
      "source": [
        "## üöÄ Advanced Usage\n",
        "\n",
        "### Different Map Sizes\n",
        "\n",
        "Test bots on different map complexities:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "run_different_maps"
      },
      "source": [
        "# Test on different map sizes\n",
        "maps = [\n",
        "    'maps/1v1/6x6_beginner.csv',\n",
        "    'maps/1v1/10x10_easy.csv',\n",
        "    'maps/1v1/14x14_medium.csv',\n",
        "]\n",
        "\n",
        "# for map_file in maps:\n",
        "#     print(f\"\\n{'='*60}\")\n",
        "#     print(f\"Testing on: {map_file}\")\n",
        "#     print(f\"{'='*60}\")\n",
        "#\n",
        "#     winner = run_single_game(\n",
        "#         player1_bot='simple',\n",
        "#         player2_bot='simple',\n",
        "#         map_file=map_file,\n",
        "#         max_turns=200,\n",
        "#         verbose=False\n",
        "#     )\n",
        "#     print(f\"Winner: Player {winner}\" if winner else \"Result: Draw\")\n",
        "\n",
        "print(\"Uncomment the code above to test different map sizes\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "next_steps"
      },
      "source": [
        "## üéì Next Steps\n",
        "\n",
        "**Experiment Ideas:**\n",
        "1. Compare different models from the same provider\n",
        "2. Test how map size affects bot performance\n",
        "3. Analyze which bots excel at different strategies\n",
        "4. Track game length and resource management\n",
        "5. Create a \"ladder\" system with Elo ratings\n",
        "\n",
        "**Code Customization:**\n",
        "1. Modify system prompts in `llm_bot.py` for different strategies\n",
        "2. Add logging to track specific metrics\n",
        "3. Create visualization of tournament brackets\n",
        "4. Export results to CSV for analysis\n",
        "5. Build a web interface for live tournaments\n",
        "\n",
        "**Advanced Tournaments:**\n",
        "1. Swiss-system tournament format\n",
        "2. Double elimination brackets\n",
        "3. Time-limited games\n",
        "4. Asymmetric maps\n",
        "5. Team battles (coming soon)\n",
        "\n",
        "**Contributing:**\n",
        "- Found a bug? Open an issue on GitHub\n",
        "- Have an improvement? Submit a pull request\n",
        "- Share your tournament results!\n",
        "\n",
        "**Resources:**\n",
        "- Repository: https://github.com/kuds/reinforce-tactics\n",
        "- Game Rules: See `reinforcetactics/game/llm_bot.py` SYSTEM_PROMPT\n",
        "- Tournament Script: `scripts/tournament.py`\n",
        "\n",
        "---\n",
        "\n",
        "**Happy Gaming! üéÆ**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "llm_bot_tournament.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
